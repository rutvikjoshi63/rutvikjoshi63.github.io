---
layout: distill
title: ML Development Process
date: 2022-10-31 06:56:00-0400
description: Neural Network Evaluation
tags: Machine Learning Evaluation math
# categories: sample-posts
giscus_comments: true
related_posts: false
featured: false
# related_publications: einstein1950meaning, einstein1905movement

authors:
  - name: Rutvik Joshi
    # url: "https://en.wikipedia.org/wiki/Albert_Einstein"
    affiliations:
      name: IIT-Bombay, VJTI

toc:
  - name: Intro
    subsections:
      - name: building an email spam classifier
  - name: Advance Algorithm
    subsections:
      - name: Error metrics for skewed datasets
      - name: Bias and variance
  - name: Calculus for Machine Learning and Data Science
    subsections:
      - name: Derivatives & Optimization
      - name: Gradients & Gradient Descent
#      - name: Bias and variance
#  - name: Adding data
# #  if a section has subsections, you can add them as follows:
#    subsections:
#      - name: Data augmentation
#      - name: Photo OCR 
#  - name: Transfer learning
##  if a section has subsections, you can add them as follows:
#    subsections:
#      - name: Pre-training
#      - name: Fine-tuning
#      - name: Benefits
#      - name: Limitations
#      - name: Examples
#  - name: Deployment

_styles: >
  .fake-img {
    background: #bbb;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
    margin-bottom: 12px;
  }
  .fake-img p {
    font-family: monospace;
    color: white;
    text-align: left;
    margin: 12px 0;
    text-align: center;
    font-size: 16px;
  }
---
## Advance Algorithm

### Error metrics for skewed datasets) 
**Precision and recall**,
![_config.yml]({{ site.baseurl }}/assets/img/AndrewNg/AdvAlgorithm_w3_PrecisionRecall.png

### Bias and variance

## Calculus for Machine Learning and Data Science
### Derivatives & Optimization
Use Logarithm, derivates

### Gradients & Gradient Descent

