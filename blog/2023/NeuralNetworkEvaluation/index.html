<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Neural Network Evaluation | Rutvik Joshi Career Portfolio</title> <meta name="author" content="Rutvik N Joshi"> <meta name="description" content="Study topics"> <meta name="keywords" content="Artificial Intelligence, Machine Learning"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://rutvikjoshi63.github.io/blog/2023/NeuralNetworkEvaluation/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Rutvik Joshi Career Portfolio</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">Rutvik Joshi</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">Resume</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Neural Network Evaluation</h1> <p class="post-meta">October 1, 2023</p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/tag/machine"> <i class="fas fa-hashtag fa-sm"></i> Machine</a>   <a href="/blog/tag/learning"> <i class="fas fa-hashtag fa-sm"></i> Learning</a>   <a href="/blog/tag/masters"> <i class="fas fa-hashtag fa-sm"></i> Masters</a>     ·   <a href="/blog/category/sample-posts"> <i class="fas fa-tag fa-sm"></i> sample-posts</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="topics-covered-in-supervised-machine-learning">Topics covered in Supervised Machine Learning</h2> <p>It is usually a good idea to perform feature scaling to help your model converge faster. This is especially true if your input features have widely different ranges of values. For that, you will use the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">StandardScaler</code></a> class from scikit-learn. This computes the z-score of your inputs. As a refresher, the z-score is given by the equation:</p> \[z = \frac{x - \mu}{\sigma}\] <p>where $\mu$ is the mean of the feature values and $\sigma$ is the standard deviation.</p> <h1 id="initialize-the-class">Initialize the class</h1> <p>scaler_linear = StandardScaler()</p> <h1 id="compute-the-mean-and-standard-deviation-of-the-training-set-then-transform-it">Compute the mean and standard deviation of the training set then transform it</h1> <p>X_train_scaled = scaler_linear.fit_transform(x_train)</p> <p>print(f”Computed mean of the training set: {scaler_linear.mean_.squeeze():.2f}”) print(f”Computed standard deviation of the training set: {scaler_linear.scale_.squeeze():.2f}”)</p> <h3 id="train-the-model">Train the model</h3> <p>Next, you will create and train a regression model. For this lab, you will use the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html" rel="external nofollow noopener" target="_blank">LinearRegression</a> class but take note that there are other <a href="https://scikit-learn.org/stable/modules/classes.html#classical-linear-regressors" rel="external nofollow noopener" target="_blank">linear regressors</a> which you can also use.</p> <h1 id="initialize-the-class-1">Initialize the class</h1> <p>linear_model = LinearRegression()</p> <h1 id="train-the-model-1">Train the model</h1> <p>linear_model.fit(X_train_scaled, y_train )</p> <h3 id="evaluate-the-model">Evaluate the Model</h3> <p>To evaluate the performance of your model, you will measure the error for the training and cross validation sets. For the training error, recall the equation for calculating the mean squared error (MSE):</p> \[J_{train}(\vec{w}, b) = \frac{1}{2m_{train}}\left[\sum_{i=1}^{m_{train}}(f_{\vec{w},b}(\vec{x}_{train}^{(i)}) - y_{train}^{(i)})^2\right]\] <p>Scikit-learn also has a built-in <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">mean_squared_error()</code></a> function that you can use. Take note though that <a href="https://scikit-learn.org/stable/modules/model_evaluation.html#mean-squared-error" rel="external nofollow noopener" target="_blank">as per the documentation</a>, scikit-learn’s implementation only divides by <code class="language-plaintext highlighter-rouge">m</code> and not <code class="language-plaintext highlighter-rouge">2*m</code>, where <code class="language-plaintext highlighter-rouge">m</code> is the number of examples.</p> <h1 id="feed-the-scaled-training-set-and-get-the-predictions">Feed the scaled training set and get the predictions</h1> <p>yhat = linear_model.predict(X_train_scaled)</p> <h1 id="use-scikit-learns-utility-function-and-divide-by-2">Use scikit-learn’s utility function and divide by 2</h1> <p>print(f”training MSE (using sklearn function): {mean_squared_error(y_train, yhat) / 2}”)</p> <p>You can then compute the MSE for the cross validation set with basically the same equation.</p> <ul> <li>Say that your training set has an input feature equal to <code class="language-plaintext highlighter-rouge">500</code> which is scaled down to <code class="language-plaintext highlighter-rouge">0.5</code> using the z-score.</li> <li>After training, your model is able to accurately map this scaled input <code class="language-plaintext highlighter-rouge">x=0.5</code> to the target output <code class="language-plaintext highlighter-rouge">y=300</code>.</li> <li>Now let’s say that you deployed this model and one of your users fed it a sample equal to <code class="language-plaintext highlighter-rouge">500</code>.</li> <li>If you get this input sample’s z-score using any other values of the mean and standard deviation, then it might not be scaled to <code class="language-plaintext highlighter-rouge">0.5</code> and your model will most likely make a wrong prediction (i.e. not equal to <code class="language-plaintext highlighter-rouge">y=300</code>).</li> </ul> <p>You will scale the cross validation set below by using the same <code class="language-plaintext highlighter-rouge">StandardScaler</code> you used earlier but only calling its <a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler.transform" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">transform()</code></a> method instead of <a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler.fit_transform" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">fit_transform()</code></a>.</p> <h1 id="scale-the-cross-validation-set-using-the-mean-and-standard-deviation-of-the-training-set">Scale the cross validation set using the mean and standard deviation of the training set</h1> <p>X_cv_scaled = scaler_linear.transform(x_cv)</p> <p>print(f”Mean used to scale the CV set: {scaler_linear.mean_.squeeze():.2f}”) print(f”Standard deviation used to scale the CV set: {scaler_linear.scale_.squeeze():.2f}”)</p> <h1 id="feed-the-scaled-cross-validation-set">Feed the scaled cross validation set</h1> <p>yhat = linear_model.predict(X_cv_scaled)</p> <h1 id="use-scikit-learns-utility-function-and-divide-by-2-1">Use scikit-learn’s utility function and divide by 2</h1> <p>print(f”Cross validation MSE: {mean_squared_error(y_cv, yhat) / 2}”)</p> <h2 id="adding-polynomial-features">Adding Polynomial Features</h2> <h3 id="create-the-additional-features">Create the additional features</h3> <p>First, you will generate the polynomial features from your training set. The code below demonstrates how to do this using the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">PolynomialFeatures</code></a> class. It will create a new input feature which has the squared values of the input <code class="language-plaintext highlighter-rouge">x</code> (i.e. degree=2).</p> <h1 id="instantiate-the-class-to-make-polynomial-features">Instantiate the class to make polynomial features</h1> <p>poly = PolynomialFeatures(degree=2, include_bias=False)</p> <h1 id="compute-the-number-of-features-and-transform-the-training-set">Compute the number of features and transform the training set</h1> <p>X_train_mapped = poly.fit_transform(x_train)</p> <h1 id="preview-the-first-5-elements-of-the-new-training-set-left-column-is-x-and-right-column-is-x2">Preview the first 5 elements of the new training set. Left column is <code class="language-plaintext highlighter-rouge">x</code> and right column is <code class="language-plaintext highlighter-rouge">x^2</code> </h1> <h1 id="note-the-enumber-in-the-output-denotes-how-many-places-the-decimal-point-should">Note: The <code class="language-plaintext highlighter-rouge">e+&lt;number&gt;</code> in the output denotes how many places the decimal point should</h1> <h1 id="be-moved-for-example-324e03-is-equal-to-3240">be moved. For example, <code class="language-plaintext highlighter-rouge">3.24e+03</code> is equal to <code class="language-plaintext highlighter-rouge">3240</code> </h1> <p>print(X_train_mapped[:5]) You will then scale the inputs as before to narrow down the range of values.</p> <h1 id="instantiate-the-class">Instantiate the class</h1> <p>scaler_poly = StandardScaler()</p> <h1 id="compute-the-mean-and-standard-deviation-of-the-training-set-then-transform-it-1">Compute the mean and standard deviation of the training set then transform it</h1> <p>X_train_mapped_scaled = scaler_poly.fit_transform(X_train_mapped)</p> <h1 id="preview-the-first-5-elements-of-the-scaled-training-set">Preview the first 5 elements of the scaled training set.</h1> <p>print(X_train_mapped_scaled[:5]) You can then proceed to train the model. After that, you will measure the model’s performance against the cross validation set. Like before, you should make sure to perform the same transformations as you did in the training set. You will add the same number of polynomial features then scale the range of values.</p> <h1 id="initialize-the-class-2">Initialize the class</h1> <p>model = LinearRegression()</p> <h1 id="train-the-model-2">Train the model</h1> <p>model.fit(X_train_mapped_scaled, y_train )</p> <h1 id="compute-the-training-mse">Compute the training MSE</h1> <p>yhat = model.predict(X_train_mapped_scaled) print(f”Training MSE: {mean_squared_error(y_train, yhat) / 2}”)</p> <h1 id="add-the-polynomial-features-to-the-cross-validation-set">Add the polynomial features to the cross validation set</h1> <p>X_cv_mapped = poly.transform(x_cv)</p> <h1 id="scale-the-cross-validation-set-using-the-mean-and-standard-deviation-of-the-training-set-1">Scale the cross validation set using the mean and standard deviation of the training set</h1> <p>X_cv_mapped_scaled = scaler_poly.transform(X_cv_mapped)</p> <h1 id="compute-the-cross-validation-mse">Compute the cross validation MSE</h1> <p>yhat = model.predict(X_cv_mapped_scaled) print(f”Cross validation MSE: {mean_squared_error(y_cv, yhat) / 2}”)</p> <p><strong>You can create a loop that contains all the steps in the previous code cells. Here is one implementation that adds polynomial features up to degree=10.</strong></p> <h1 id="initialize-lists-containing-the-lists-models-and-scalers">Initialize lists containing the lists, models, and scalers</h1> <p>train_mses = [] cv_mses = [] models = [] scalers = []</p> <h1 id="loop-over-10-times-each-adding-one-more-degree-of-polynomial-higher-than-the-last">Loop over 10 times. Each adding one more degree of polynomial higher than the last.</h1> <p>for degree in range(1,11):</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Add polynomial features to the training set
poly = PolynomialFeatures(degree, include_bias=False)
X_train_mapped = poly.fit_transform(x_train)

# Scale the training set
scaler_poly = StandardScaler()
X_train_mapped_scaled = scaler_poly.fit_transform(X_train_mapped)
scalers.append(scaler_poly)

# Create and train the model
model = LinearRegression()
model.fit(X_train_mapped_scaled, y_train )
models.append(model)

# Compute the training MSE
yhat = model.predict(X_train_mapped_scaled)
train_mse = mean_squared_error(y_train, yhat) / 2
train_mses.append(train_mse)

# Add polynomial features and scale the cross validation set
poly = PolynomialFeatures(degree, include_bias=False)
X_cv_mapped = poly.fit_transform(x_cv)
X_cv_mapped_scaled = scaler_poly.transform(X_cv_mapped)

# Compute the cross validation MSE
yhat = model.predict(X_cv_mapped_scaled)
cv_mse = mean_squared_error(y_cv, yhat) / 2
cv_mses.append(cv_mse)
</code></pre></div></div> <h1 id="plot-the-results">Plot the results</h1> <p>degrees=range(1,11) utils.plot_train_cv_mses(degrees, train_mses, cv_mses, title=”degree of polynomial vs. train and CV MSEs”)</p> <h1 id="get-the-model-with-the-lowest-cv-mse-add-1-because-list-indices-start-at-0">Get the model with the lowest CV MSE (add 1 because list indices start at 0)</h1> <h1 id="this-also-corresponds-to-the-degree-of-the-polynomial-added">This also corresponds to the degree of the polynomial added</h1> <p>degree = np.argmin(cv_mses) + 1 print(f”Lowest CV MSE is found in the model with degree={degree}”)</p> </div> </article><div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=localStorage.getItem("theme"),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"rutvikjoshi63/rutvikjoshi63.github.io","data-repo-id":"MDEwOlJlcG9zaXRvcnk2MDAyNDM2NQ==","data-category":"comments","data-category-id":"DIC_kwDOA5PmLc4CTBt6","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Rutvik N Joshi. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js"></script> <script defer src="/assets/js/common.js"></script> <script defer src="/assets/js/copy_code.js" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>